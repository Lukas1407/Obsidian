- Training a model with new information interferes with previously learned knowledge 
- Abrupt performance decrease or old knowledge completely overwritten by the new one

Main conclusions: 
1. Lower layers representations remain stable through training on the new task
2. Higher layer representations change significantly 
3. Empirical evidence that forgetting follows semantically consistent patterns (i.e., degree of forgetting related to task similarity)