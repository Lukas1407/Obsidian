{
  "main": {
    "id": "70640a355c7ea185",
    "type": "split",
    "children": [
      {
        "id": "742c96c9a5b03e01",
        "type": "tabs",
        "children": [
          {
            "id": "40919fd0cbae7b99",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "University Lectures/Current/Reinforcement Learning/notes/Reinforcement Learning.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "cfe35d83ef45c382",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "University Lectures/Current/Reinforcement Learning/notes/Questions.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "4cc51c38d45edb41",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "University Lectures/Current/Reinforcement Learning/notes/Off-Policy Actor-Critic Algorithms.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "f9702599bfe6c221",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Soft-Actor Critic (SAC).md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "9eae33ccafd4263b",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Variational Inference.md",
                "mode": "source",
                "source": false
              }
            }
          }
        ],
        "currentTab": 4
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "73fad221df09b14c",
    "type": "split",
    "children": [
      {
        "id": "3bcf1f711f479d5e",
        "type": "tabs",
        "dimension": 71.20954003407155,
        "children": [
          {
            "id": "fe6fda8b5d3c97d9",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "42c3e66d6a18aeed",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {}
            }
          },
          {
            "id": "e2d5877c59d1a271",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "byCreatedTime"
              }
            }
          }
        ],
        "currentTab": 2
      },
      {
        "id": "e5d81ef363e6aad6",
        "type": "tabs",
        "dimension": 28.79045996592845,
        "children": [
          {
            "id": "785b9852cdae2079",
            "type": "leaf",
            "state": {
              "type": "calendar",
              "state": {}
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 289.5
  },
  "right": {
    "id": "59a9d4a25d24dd44",
    "type": "split",
    "children": [
      {
        "id": "47c55f163724204e",
        "type": "tabs",
        "dimension": 68.0306905370844,
        "children": [
          {
            "id": "7bffd68f3e07a41b",
            "type": "leaf",
            "state": {
              "type": "timeline",
              "state": {}
            }
          }
        ]
      },
      {
        "id": "2a18b6abba14ce71",
        "type": "tabs",
        "dimension": 31.9693094629156,
        "children": [
          {
            "id": "525a2ceb22f5a15a",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "Variational Inference.md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "164fe6bf0ca0d133",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "Variational Inference.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "d7b52cc6005274b6",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              }
            }
          },
          {
            "id": "6ef1b157567c7634",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "Variational Inference.md"
              }
            }
          },
          {
            "id": "441b1c9aa34d05bc",
            "type": "leaf",
            "state": {
              "type": "side-panel-control-view",
              "state": {}
            }
          }
        ],
        "currentTab": 4
      }
    ],
    "direction": "horizontal",
    "width": 355.5
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": true,
      "graph:Open graph view": true,
      "canvas:Create new canvas": true,
      "daily-notes:Open today's daily note": true,
      "templates:Insert template": true,
      "command-palette:Open command palette": true,
      "obsidian-markdown-formatting-assistant-plugin:Open Markdown Formatting Assistant": true,
      "table-editor-obsidian:Advanced Tables Toolbar": true,
      "obsidian-day-planner:Timeline": true,
      "templater-obsidian:Templater": true,
      "omnisearch:Omnisearch": true,
      "obsidian-excalidraw-plugin:Create new drawing": false
    }
  },
  "active": "9eae33ccafd4263b",
  "lastOpenFiles": [
    "Variational Inference.md",
    "University Lectures/Current/Reinforcement Learning/notes/Questions.md",
    "Soft-Actor Critic (SAC).md",
    "images/Pasted image 20240708123401.png",
    "images",
    "University Lectures/Current/Reinforcement Learning/notes/Off-Policy Actor-Critic Algorithms.md",
    "University Lectures/Current/Reinforcement Learning/notes/Maximum Entropy Reinforcement Learning.md",
    "Twin-Delayed DDPG (TD3).md",
    "Deep Deterministic Policy Gradient (DDPG).md",
    "University Lectures/Current/Reinforcement Learning/notes/QT-Opt.md",
    "University Lectures/Current/Reinforcement Learning/notes/Differential Trust Region Layers.md",
    "University Lectures/Current/Reinforcement Learning/notes/Trust Region Policy Optimization (TRPO).md",
    "University Lectures/Current/Reinforcement Learning/notes/Policy Optimization.md",
    "University Lectures/Current/Reinforcement Learning/notes/Proximal Policy Optimization (PPO).md",
    "University Lectures/Current/Reinforcement Learning/notes/Trust-Region Policy Optimization (TRPO).md",
    "University Lectures/Current/Reinforcement Learning/notes/Natural Gradients.md",
    "University Lectures/Current/Reinforcement Learning/notes/Fisher Information Matrix (FIM).md",
    "University Lectures/Current/Reinforcement Learning/notes/images/Pasted image 20240404094039.png",
    "University Lectures/Current/Reinforcement Learning/notes/images/Pasted image 20240404093917.png",
    "University Lectures/Current/Reinforcement Learning/notes/Lagrangian Multipliers.md",
    "University Lectures/Current/Reinforcement Learning/notes/Taxonomy of RL Algorithms.md",
    "University Lectures/Current/Reinforcement Learning/notes/Anatomy of RL Algorithms.md",
    "University Lectures/Current/Reinforcement Learning/notes/Value-Function.md",
    "Distributional RL.md",
    "University Lectures/Current/Reinforcement Learning/notes/Value-Function Approximation.md",
    "University Lectures/Current/Reinforcement Learning/notes/Temporal Difference Learning.md",
    "University Lectures/Current/Reinforcement Learning/notes/Policy Iteration.md",
    "University Lectures/Current/Reinforcement Learning/notes/Monte-Carlo Estimation.md",
    "University Lectures/Current/Reinforcement Learning/notes/images/Pasted image 20240708104420.png",
    "University Lectures/Current/Reinforcement Learning/notes/Log-Ratio Trick.md",
    "University Lectures/Current/Reinforcement Learning/notes/Bias-Variance Trade-off.md",
    "University Lectures/Current/Reinforcement Learning/notes/images/VI_example-ezgif.com-speed.gif",
    "University Lectures/Current/Reinforcement Learning/notes/images/Pasted image 20240708082827.png",
    "University Lectures/Current/Reinforcement Learning/notes/images/Untitled.png",
    "University Lectures/Current/Reinforcement Learning/notes/images/Pasted image 20240708081455.png",
    "University Lectures/Current/Reinforcement Learning/notes/images/Pasted image 20240309122455.png",
    "University Lectures/Current/Reinforcement Learning/books",
    "University Lectures/Current/Reinforcement Learning/exercises/6_offline_rl_solutions.ipynb",
    "University Lectures/Current/Reinforcement Learning/exercises/6_offline_rl.ipynb",
    "University Lectures/Current/Reinforcement Learning/exercises/5_stochastic_search_upload.ipynb",
    "University Lectures/Current/Reinforcement Learning/exercises/5_stochastic_search_solutions.ipynb",
    "University Lectures/Current/Reinforcement Learning/exercises/4_mbrl_solutions.ipynb",
    "University Lectures/Current/Reinforcement Learning/exercises/4_mbrl.ipynb",
    "University Lectures/Current/Reinforcement Learning/exercises/3_policy_gradients_solutions.ipynb",
    "University Lectures/Current/Reinforcement Learning/exercises/3_policy_gradients.ipynb",
    "University Lectures/Current/Software Technik 2/notes/images/Pasted image 20240707144352.png",
    "Obsidian/Untitled.canvas"
  ]
}